{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 다중 분류 실습(로이터 기사)\n",
        "### 로이터(Reuters) 뉴스 데이터셋은 총 46개의 서로 다른 주제(클래스)로 분류된 뉴스 기사들로 구성되어 있다. 각 주제는 0부터 45까지의 정수로 인코딩되어 있다.\n",
        "\n",
        "0: `cocoa`  \n",
        "1: `grain`  \n",
        "2: `veg-oil`  \n",
        "3: `earn`  \n",
        "4: `acq`  \n",
        "5: `wheat`  \n",
        "6: `copper`  \n",
        "7: `housing`  \n",
        "8: `money-supply`  \n",
        "9: `coffee`  \n",
        "10: `sugar`  \n",
        "...  \n",
        "46개의 주제는 레이블 값으로 train_label에 저장되어 있다."
      ],
      "metadata": {
        "id": "o9qvGTuDuHNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "zkmT3Y_8uLYd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 로이터 기사 데이터셋 불러오기\n",
        "from keras.datasets import reuters\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpN5cBrkuhn8",
        "outputId": "b8642dc1-bb76-4a6d-f057-7b7ac4ae66b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 1s 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape # 1차원 배열(벡터)이며 배열의 크기는 8982이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pg28gvQvFcZ",
        "outputId": "8a31cb2f-fffb-4dce-f522-8505fe44226f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982,)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0] # 정수 인덱스로 매핑한 결과"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WdMgUezvNOa",
        "outputId": "66c32a98-0cb5-4e39-a17b-11e5b096ae52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 2,\n",
              " 8,\n",
              " 43,\n",
              " 10,\n",
              " 447,\n",
              " 5,\n",
              " 25,\n",
              " 207,\n",
              " 270,\n",
              " 5,\n",
              " 3095,\n",
              " 111,\n",
              " 16,\n",
              " 369,\n",
              " 186,\n",
              " 90,\n",
              " 67,\n",
              " 7,\n",
              " 89,\n",
              " 5,\n",
              " 19,\n",
              " 102,\n",
              " 6,\n",
              " 19,\n",
              " 124,\n",
              " 15,\n",
              " 90,\n",
              " 67,\n",
              " 84,\n",
              " 22,\n",
              " 482,\n",
              " 26,\n",
              " 7,\n",
              " 48,\n",
              " 4,\n",
              " 49,\n",
              " 8,\n",
              " 864,\n",
              " 39,\n",
              " 209,\n",
              " 154,\n",
              " 6,\n",
              " 151,\n",
              " 6,\n",
              " 83,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 155,\n",
              " 11,\n",
              " 15,\n",
              " 7,\n",
              " 48,\n",
              " 9,\n",
              " 4579,\n",
              " 1005,\n",
              " 504,\n",
              " 6,\n",
              " 258,\n",
              " 6,\n",
              " 272,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 134,\n",
              " 44,\n",
              " 11,\n",
              " 15,\n",
              " 16,\n",
              " 8,\n",
              " 197,\n",
              " 1245,\n",
              " 90,\n",
              " 67,\n",
              " 52,\n",
              " 29,\n",
              " 209,\n",
              " 30,\n",
              " 32,\n",
              " 132,\n",
              " 6,\n",
              " 109,\n",
              " 15,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 훈련 데이터의 첫 번째 기사를 디코딩하여 텍스트로 변환한다."
      ],
      "metadata": {
        "id": "Ip5vjzFTwNQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) # 편의성을 위해 단어 사전과 반대로 인덱스를 key, 단어를 value로 지정한다.\n",
        "\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]]) # 원문으로 저장. 실제 단어가 3부터 시작. 찾지 못한 경우 '?' 반환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzkzDEnavPke",
        "outputId": "34a9bf84-386e-4c91-ffca-9a438823457c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "550378/550378 [==============================] - 1s 1us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_newswire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "kfO65AyFyGCt",
        "outputId": "e8375121-b1b3-407b-da04-1fe397a99015"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onpPZkROyKsC",
        "outputId": "cd1c9edb-d177-4d37-fac5-56d173f44f12"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 준비\n",
        "# 정수 인덱스로 매핑되어 있는 데이터를 원-핫 인코딩으로 변환하기 위한 함수\n",
        "def to_one_hot_data(sequences, dimension=10000): # dimension 값은 단어 사전의 크기에 해당된다. 기본값: 10000\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1\n",
        "\n",
        "  return results\n",
        "\n",
        "# 데이터 변환\n",
        "x_train = to_one_hot_data(train_data)\n",
        "x_test = to_one_hot_data(test_data)\n"
      ],
      "metadata": {
        "id": "8ZmUdku2yNlc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6282U41Yz3sO",
        "outputId": "6272a064-7191-41ee-cc3a-b97b59c98f42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3,  4,  3, ..., 25,  3, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 준비\n",
        "def to_one_hot_labels(labels, dimension=46): # 레이블 46개\n",
        "   results = np.zeros((len(labels), dimension))\n",
        "   # 만약 레이블이 1000개이고 dimension이 46이라면, 배열의 크기가 (1000, 46)인 2차원 배열이 생성되고 0으로 초기화된다.\n",
        "\n",
        "   # sequence는 텍스트 데이터를 정수 인덱스로 변환한 시퀀스\n",
        "   for i, sequence in enumerate(labels):\n",
        "    results[i, sequence] = 1\n",
        "\n",
        "   return results\n",
        "\n",
        "one_hot_train_labels = to_one_hot_labels(train_labels)\n",
        "one_hot_test_labels = to_one_hot_labels(test_labels)"
      ],
      "metadata": {
        "id": "ktz9icqUz7ki"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### results의 모든 값이 0으로 초기화된 상태이므로 [0, 0, 0, 0, ..., 0]과 같이 0이 46개인 배열의 형태이다. 레이블이 [1, 0, 0, 0, ..., 0], [0, 1, 0, 0, ..., 0]과 같이 표현된다. 첫 번째 데이터의 인덱스인 경우 i = 0이고 두 번째 데이터의 인덱스인 경우 i = 1이다.\n",
        "\n",
        "###### 0: cocoa, 1: grain, 2: veg-oil, 3: earn, 4: acq, 5: wheat\n",
        "[1, 0, 0, 0, ..., 0]\n",
        "[0, 1, 0, 0, ..., 0]\n",
        "[0, 0, 1, 0, ..., 0]"
      ],
      "metadata": {
        "id": "GoROjJ_z52DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 범주형 데이터로 변환하기\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "cggTHzU_7QKC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 구성하기\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "metadata": {
        "id": "1I19BE0k95js"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 첫 번째 Dense Layer 추가\n",
        "###### 두 번째 Dense Layer 추가. 앞선 출력이 자동으로 다음 레이어의 입력으로 전달된다.\n",
        "###### 세 번째 Layer 추가. softmax 함수는 다중 클래스 분류 문제에서 각 클래스에 대한 확률을 출력하는 데 사용된다."
      ],
      "metadata": {
        "id": "g3zuFoT5_GRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 요약 정보\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLf3LX4E_RbI",
        "outputId": "4c6eb84d-bd6e-4686-8583-8f3fcf1339ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                640064    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 46)                2990      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7KodHmyR_bnO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분할 train:valid: = 9:1\n",
        "val_dataset = x_train[:1000]\n",
        "train_dataset = x_train[1000:]\n",
        "val_label = one_hot_train_labels[:1000]\n",
        "train_label = one_hot_train_labels[1000:]"
      ],
      "metadata": {
        "id": "VR8ylnQGAAOa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, train_label, epochs=20, batch_size=512, validation_data=(val_dataset, val_label))\n",
        "model.save('Sequential_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81csya-kB0Uc",
        "outputId": "973e4d35-7184-4b87-8bd5-3ffa828a1292"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0693 - accuracy: 0.9627 - val_loss: 1.1230 - val_accuracy: 0.8050\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0694 - accuracy: 0.9593 - val_loss: 1.1274 - val_accuracy: 0.8070\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0686 - accuracy: 0.9588 - val_loss: 1.1433 - val_accuracy: 0.8050\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0706 - accuracy: 0.9599 - val_loss: 1.1454 - val_accuracy: 0.8030\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0684 - accuracy: 0.9580 - val_loss: 1.1505 - val_accuracy: 0.8130\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 0s 21ms/step - loss: 0.0707 - accuracy: 0.9600 - val_loss: 1.1592 - val_accuracy: 0.8060\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0688 - accuracy: 0.9587 - val_loss: 1.1280 - val_accuracy: 0.8070\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0684 - accuracy: 0.9615 - val_loss: 1.1479 - val_accuracy: 0.8120\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.0687 - accuracy: 0.9585 - val_loss: 1.1336 - val_accuracy: 0.8080\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 0s 20ms/step - loss: 0.0672 - accuracy: 0.9612 - val_loss: 1.1714 - val_accuracy: 0.8090\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.0677 - accuracy: 0.9614 - val_loss: 1.1638 - val_accuracy: 0.8090\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.0670 - accuracy: 0.9605 - val_loss: 1.1358 - val_accuracy: 0.8060\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0675 - accuracy: 0.9598 - val_loss: 1.2089 - val_accuracy: 0.8050\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.0682 - accuracy: 0.9584 - val_loss: 1.1382 - val_accuracy: 0.8110\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0679 - accuracy: 0.9585 - val_loss: 1.1598 - val_accuracy: 0.8130\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0688 - accuracy: 0.9590 - val_loss: 1.1645 - val_accuracy: 0.8120\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.0675 - accuracy: 0.9583 - val_loss: 1.1627 - val_accuracy: 0.8090\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0684 - accuracy: 0.9614 - val_loss: 1.1866 - val_accuracy: 0.8050\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.0682 - accuracy: 0.9583 - val_loss: 1.1613 - val_accuracy: 0.8110\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 0s 17ms/step - loss: 0.0672 - accuracy: 0.9587 - val_loss: 1.2102 - val_accuracy: 0.8060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, x_test, one_hot_test_labels):\n",
        "    test_loss, test_acc = model.evaluate(x_test, one_hot_test_labels)\n",
        "    return test_acc\n",
        "\n",
        "# 모델 테스트 model.evaluate()\n",
        "test_accuracy = evaluate_model(model, x_test, one_hot_test_labels)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCAbqIymGNA8",
        "outputId": "772aa4a9-2751-491c-e7d6-c28c6d9b0dc8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 0s 3ms/step - loss: 1.4012 - accuracy: 0.7769\n",
            "Test Accuracy: 0.7769367694854736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# 저장된 모델의 파일 경로를 지정합니다.\n",
        "model_path = 'Sequential_model.h5'\n",
        "\n",
        "# 모델 불러오기\n",
        "model = load_model(model_path)"
      ],
      "metadata": {
        "id": "iLxCejhBUSgk"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 추론\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def tokenize_and_pad(text, word_index, max_length):\n",
        "    tokenizer = Tokenizer(num_words=10000)\n",
        "    tokenizer.word_index = word_index\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "    return padded_sequences\n",
        "\n",
        "def preprocess_text(text, word_index, max_sequence_length=10000):\n",
        "    # 정수 인덱스로 변환하는 함수\n",
        "    words = text.lower().split()\n",
        "    sequence = [word_index[word] if word in word_index else 0 for word in words] # 리스트 컴프리헨션\n",
        "    sequence = sequence[:max_sequence_length]\n",
        "    return sequence\n",
        "\n",
        "\n",
        "def predict_category(model, text, word_index):\n",
        "    # 새로운 기사를 입력받아 카테고리를 예측하는 함수\n",
        "    sequence = preprocess_text(text, word_index)\n",
        "    input_data = np.zeros((1, 10000))  # 모델이 기대하는 입력 형태로 변경\n",
        "    for i, idx in enumerate(sequence):\n",
        "        input_data[0, idx] = 1\n",
        "\n",
        "    prediction = model.predict(input_data)\n",
        "    predicted_category_index = np.argmax(prediction)\n",
        "    return predicted_category_index"
      ],
      "metadata": {
        "id": "1icurInBDBNF"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "sequence = []\n",
        "\n",
        "for word in words:\n",
        "    if word in word_index:\n",
        "        # word가 word_index 딕셔너리에 존재하는 경우, 인덱스를 sequence 리스트에 추가\n",
        "        sequence.append(word_index[word])\n",
        "    else:\n",
        "        # word가 word_index 딕셔너리에 존재하지 않는 경우, 0을 sequence 리스트에 추가\n",
        "        sequence.append(0)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "weWH5YkvD8a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주제의 인덱스를 주제의 실제 레이블로 매핑하는 딕셔너리\n",
        "category_index_to_label = {\n",
        "    0: 'cocoa',\n",
        "    1: 'grain',\n",
        "    2: 'veg-oil',\n",
        "    3: 'earn',\n",
        "    4: 'acq',\n",
        "    5: 'wheat',\n",
        "    6: 'copper',\n",
        "    7: 'housing',\n",
        "    8: 'money-supply',\n",
        "    9: 'coffee',\n",
        "    10: 'sugar',\n",
        "    11: 'trade',\n",
        "    12: 'reserves',\n",
        "    13: 'ship',\n",
        "    14: 'cotton',\n",
        "    15: 'carcass',\n",
        "    16: 'crude',\n",
        "    17: 'nat-gas',\n",
        "    18: 'cpi',\n",
        "    19: 'money-fx',\n",
        "    20: 'interest',\n",
        "    21: 'gnp',\n",
        "    22: 'meal-feed',\n",
        "    23: 'alum',\n",
        "    24: 'oilseed',\n",
        "    25: 'gold',\n",
        "    26: 'tin',\n",
        "    27: 'strategic-metal',\n",
        "    28: 'livestock',\n",
        "    29: 'retail',\n",
        "    30: 'ipi',\n",
        "    31: 'iron-steel',\n",
        "    32: 'rubber',\n",
        "    33: 'heat',\n",
        "    34: 'jobs',\n",
        "    35: 'lei',\n",
        "    36: 'bop',\n",
        "    37: 'zinc',\n",
        "    38: 'orange',\n",
        "    39: 'pet-chem',\n",
        "    40: 'dlr',\n",
        "    41: 'gas',\n",
        "    42: 'silver',\n",
        "    43: 'wpi',\n",
        "    44: 'hog',\n",
        "    45: 'lead'\n",
        "}"
      ],
      "metadata": {
        "id": "HBWujuIqWX1z"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_path = 'article1.txt'\n",
        "\n",
        "# 입력 텍스트를 토큰화하고 정수 인덱스로 변환\n",
        "padded_input = tokenize_and_pad(article_path, word_index, max_length=10000)\n",
        "\n",
        "# 모델을 사용하여 예측\n",
        "predicted_category_index = predict_category(model, article_path, word_index)\n",
        "\n",
        "# 인덱스를 실제 주제로 변환\n",
        "predicted_category_label = category_index_to_label[predicted_category_index]\n",
        "print(f'예측된 카테고리 인덱스: {predicted_category_index}, 주제: {predicted_category_label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw-w1QOUJm_d",
        "outputId": "7b425faa-92d1-458a-f221-e3d7a069ca51"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n",
            "예측된 카테고리 인덱스: 3, 주제: earn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_path = 'article2.txt'\n",
        "\n",
        "# 입력 텍스트를 토큰화하고 정수 인덱스로 변환\n",
        "padded_input = tokenize_and_pad(article_path, word_index, max_length=10000)\n",
        "\n",
        "# 모델을 사용하여 예측\n",
        "predicted_category_index = predict_category(model, article_path, word_index)\n",
        "\n",
        "# 인덱스를 실제 주제로 변환\n",
        "predicted_category_label = category_index_to_label[predicted_category_index]\n",
        "print(f'예측된 카테고리 인덱스: {predicted_category_index}, 주제: {predicted_category_label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr-RHWnaMzbz",
        "outputId": "3ebd903d-2b29-4460-97b6-4541d2a13aed"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "예측된 카테고리 인덱스: 3, 주제: earn\n"
          ]
        }
      ]
    }
  ]
}